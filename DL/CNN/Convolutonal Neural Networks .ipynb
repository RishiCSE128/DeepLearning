{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The human brain processes images based on features. Convolution Neural netoworks are used to process images and produce labels. An image is reprented as a matrix $M_{m\\times n}$(B/W as 2D and color as 3D with 3rd dimension be the color channel $\\{A,R,G,B\\}$), each cell has a value of $[0,255]$. \n",
    "\n",
    "![](confusing_pics.jpg)\n",
    "\n",
    "\n",
    "__4 Steps to build a CNN__\n",
    "1. Convoluton \n",
    "2. Max Pooling \n",
    "3. Flattening \n",
    "4. Full Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Convolution \n",
    "\n",
    "The convolution is defined as a combined integral of two function and it shows how one function modifies the other, mathematically defined as $(f*g)(t)=\\int_{-\\infty}^{\\infty}f(\\tau)g(t-\\tau)d\\tau$. This paper[2] introduces the mathematical foundation about CNN. \n",
    "\n",
    "Given a binary matrix $M \\in \\{ 0,1 \\}^{m\\times n}|m_{i,j}\\in M$ and a __Feature detector__ matrix $F \\in \\{0,1\\}^{3\\times3}$ (The feature detector is also called, __Kernel__ or __Filter__ ), the convolution is defined as $ M \\otimes F \\ni c_{i,j} = \\sum f_{i,j}.m_{i,j} $ i.e. it result a matrix with elements as number of matches by __Striding__ the filter over $M$. Typically the Stride is set to 2. The result is called the __feature map__. The Convolution process basically maps to another matrix which has higher weights to the region which corresponds higher similarity to the feature detector. This resembles the process human brain followes, it looks for features.\n",
    "\n",
    "$ \\begin{bmatrix} \n",
    "    0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "    0 & 1 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "    0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ \n",
    "    0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "    0 & 1 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "    0 & 0 & 1 & 1 & 1 & 0 & 0 \\\\\n",
    "    0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "   \\end{bmatrix} \\otimes \n",
    "   \\begin{bmatrix}\n",
    "   0 & 0 & 1 \\\\\n",
    "   1 & 0 & 0 \\\\\n",
    "   0 & 1 & 1 \\\\\n",
    "   \\end{bmatrix} = \n",
    "   \\begin{bmatrix}\n",
    "   0 & 1 & 0 & 0 & 0 \\\\ \n",
    "   0 & 1 & 1 & 1 & 0 \\\\\n",
    "   1 & 0 & 1 & 2 & 1 \\\\\n",
    "   1 & 4 & 2 & 1 & 0 \\\\\n",
    "   0 & 0 & 1 & 2 & 1 \\\\\n",
    "   \\end{bmatrix}$\n",
    "   \n",
    "In the process there will me a Set of feature detectors (each highlights a specific property) called the Feature space $\\mathcal{F}=\\{F_i\\}$ each feature would generate a feature map, thus a __Convolved Space__ is generated. $\\mathcal{C}=\\{C_i = M \\otimes F_i | \\forall F_i \\in \\mathcal{F}\\}$. Gimp[3] has a convolution tool, that does convolution using several feature detectors.\n",
    "\n",
    "### Rectified Linear Unit (ReLu) Layer \n",
    "The rectifier function, as discussed in ANN section is defined as $\\phi(x)=max(x,0)$, increses the non-linearity. Images are natively non-linear in nature, however matrix transformation such as convolution tends to introduces linearity into the transformed on, thus to retain non-linearity in the image, ReLu is used [4]. The paper [5] proposes a parametric ReLu that improves accuracy without sacrificing any performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Max Pooling\n",
    "Images which are given for training has various orientation, shades etc. which affects the matrix siginificantly. which is tackled by max-pooling, the property is called __spacial invarience__. The pooling is defied as srtiding a maxtrix $P_{2\\times 2}$ over the feature map and record a statistics from the feature map. If he stat is Max then it's called max-pooling, other varient is __Min-pooling__ or sub-sampling, __Average-pooling__ [6]. A nice visualization of convolution process can be found here [7]\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "   0 & 1 & 0 & 0 & 0 \\\\ \n",
    "   0 & 1 & 1 & 1 & 0 \\\\\n",
    "   1 & 0 & 1 & 2 & 1 \\\\\n",
    "   1 & 4 & 2 & 1 & 0 \\\\\n",
    "   0 & 0 & 1 & 2 & 1 \\\\\n",
    "   \\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "    1 & 1 & 0 \\\\\n",
    "    4 & 2 & 0 \\\\\n",
    "    0 & 2 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "The pooling process contributes the following,\n",
    "1. Maintains special invarience by keeping the features \n",
    "2. Reduces the size which helps, preventing Over-fitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Fattening\n",
    "In this process a pooled feature map is converted into a vector, which will be used as the input layer of the neural network, the complete process is given below\n",
    "\n",
    "$\n",
    "\\begin{bmatrix} \n",
    "    0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "    0 & 1 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "    0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ \n",
    "    0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "    0 & 1 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "    0 & 0 & 1 & 1 & 1 & 0 & 0 \\\\\n",
    "    0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "   \\end{bmatrix} \\otimes \n",
    "   \\begin{bmatrix}\n",
    "   0 & 0 & 1 \\\\\n",
    "   1 & 0 & 0 \\\\\n",
    "   0 & 1 & 1 \\\\\n",
    "   \\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "   0 & 1 & 0 & 0 & 0 \\\\ \n",
    "   0 & 1 & 1 & 1 & 0 \\\\\n",
    "   1 & 0 & 1 & 2 & 1 \\\\\n",
    "   1 & 4 & 2 & 1 & 0 \\\\\n",
    "   0 & 0 & 1 & 2 & 1 \\\\\n",
    "   \\end{bmatrix} \\rightarrow\n",
    "\\begin{bmatrix}\n",
    "    1 & 1 & 0 \\\\\n",
    "    4 & 2 & 0 \\\\\n",
    "    0 & 2 & 1 \\\\\n",
    "\\end{bmatrix} \\rightarrow\n",
    "\\begin{bmatrix}\n",
    "    1 \\\\ 1 \\\\ 0 \\\\\n",
    "    4 \\\\ 2 \\\\ 0 \\\\\n",
    "    0 \\\\ 2 \\\\ 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Full Connection\n",
    "The flattend vector is fed into the ANN, the hidden layers are ment to be Fully-connected (Dense). The ANN will use the features to learn relationship between them and corelates to the corresponsing label given to them. The output layer would have neuron equals to number of classes. During traing process, the hidden neuron gets trained and extracts features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax & Cross-Entropy Function\n",
    "The output layer of an ANN is a measure of probabilstic approximation, for an $n$-class classification problem the output layer consists of $n$ neurons, the sum of thei synaptic-wights is always $1$. Now, how is it possible, to have values assigned to them without any mutual connection?, the answer is the neurons dont know this, the values are normalised by a function called __Softmax__ [8] or Normalised-Exponential function. Mathematically its is a _generalization of logistic functio that squashes a vector $X\\in \\mathbb{R}^k$ of arbitrary values into a vector of same dimension with values within $[0,1]$ such that $\\sum X=1$_ Mathematiacally, softmax function is expressed as, $f_i(z)=\\frac{e^{z_j}}{\\sum_{k}e^{z_k}}$\n",
    "\n",
    "The __Cross-enropy__ function [9] is written as, $L_i = -log\\bigg(\\frac{ e^{f_{y_i}} }{\\sum_j e^{f_j}}\\bigg)$,$H(p,q)=-\\sum_x p(x)log\\bigg( q(x)\\bigg) $ is a cost function like __MSE__, but preferred for CNN after using _softmax_ which is called loss function in this context. After classifying a dog's picture, applying Softmax, assume that the two output neurons (dog, cat) become $q(x) = \\begin{bmatrix} 0.9 \\\\ 0.1 \\end{bmatrix}$ the actual label was $p(x)=\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ the loss is $H(p,q)$\n",
    "\n",
    "The follwing gives a concrete understanding of the usage of cross-entropy with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# two tables of classification result \n",
    "# using two NN are given \n",
    "nn1 = pd.read_csv('cat_dog_NN1.csv')\n",
    "nn2 = pd.read_csv('cat_dog_NN2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>dog_pred</th>\n",
       "      <th>cat_pred</th>\n",
       "      <th>dog</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row  dog_pred  cat_pred  dog  cat\n",
       "0    1       0.9       0.1    1    0\n",
       "1    2       0.1       0.9    0    1\n",
       "2    3       0.4       0.6    1    0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1 # result from ANN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>dog_pred</th>\n",
       "      <th>cat_pred</th>\n",
       "      <th>dog</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row  dog_pred  cat_pred  dog  cat\n",
       "0    1       0.6       0.4    1    0\n",
       "1    2       0.3       0.7    0    1\n",
       "2    3       0.1       0.9    1    0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn2 # result from ANN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cce(x,y):   #classificaion error, takes two lists \n",
    "    sum = 0\n",
    "    for i in range(len(x)):\n",
    "        sum += round(x[i]) ^ y[i] #rounding [0,1] to {0,1}\n",
    "    return round(sum/len(x),3)   \n",
    "\n",
    "def mse(x,y):  # MSE\n",
    "    sum = 0\n",
    "    for i in range(len(x)):\n",
    "        sum += (x[i] - y[i])**2 \n",
    "    return round(sum/len(x),3)\n",
    "    \n",
    "def cef(x,y):  # Cross-entropy \n",
    "    sum = 0\n",
    "    import math\n",
    "    for i in range(len(x)):\n",
    "        sum += y[i]* math.log10(x[i])\n",
    "    return round(-1*sum , 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp1 = nn1['dog_pred'].values.tolist()\n",
    "d1 = nn1['dog'].values.tolist() \n",
    "cp1 = nn1['cat_pred'].values.tolist()\n",
    "c1 = nn1['cat'].values.tolist()\n",
    "\n",
    "dp2 = nn2['dog_pred'].values.tolist()\n",
    "d2 = nn2['dog'].values.tolist() \n",
    "cp2 = nn2['cat_pred'].values.tolist()\n",
    "c2 = nn2['cat'].values.tolist()\n",
    "\n",
    "nn1_cce = (cce(dp1,d1)+cce(cp1,c1))/2\n",
    "nn2_cce = (cce(dp2,d2)+cce(cp2,c2))/2\n",
    "\n",
    "nn1_mse = (mse(dp1,d1)+mse(cp1,c1))\n",
    "nn2_mse = (mse(dp2,d2)+mse(cp2,c2))\n",
    "\n",
    "nn1_cef = (cef(dp1,d1)+cef(cp1,c1))\n",
    "nn2_cef = (cef(dp2,d2)+cef(cp2,c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calssificatin error : NN1 = 0.333        NN2 = 0.333       def = 0.0\n",
      "Mean Squared error  : NN1 = 0.254        NN2 = 0.706       def = 0.452\n",
      "Cross-entropy error : NN1 = 0.49         NN2 = 1.377       def = 0.887\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(f\"Calssificatin error : NN1 = {nn1_cce}  \\\n",
    "      NN2 = {nn2_cce} \\\n",
    "      def = {round(math.sqrt((nn1_cce - nn2_cce)**2),3)}\")  \n",
    "\n",
    "print(f\"Mean Squared error  : NN1 = {nn1_mse}  \\\n",
    "      NN2 = {nn2_mse} \\\n",
    "      def = {round(math.sqrt((nn1_mse - nn2_mse)**2),3)}\")\n",
    "\n",
    "print(f\"Cross-entropy error : NN1 = {nn1_cef}  \\\n",
    "       NN2 = {nn2_cef} \\\n",
    "      def = {round(math.sqrt((nn1_cef - nn2_cef)**2),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it shows in the result, Cross-entropy distinguishes between the two resutls better than others, this happens due to its lograrithmic nature which can capture changes in a very small scale. However Cross-entropy is recomanded for classification problems only, for regression problems MSE is preffered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n",
    "1. https://www.researchgate.net/publication/2985446_Gradient-Based_Learning_Applied_to_Document_Recognition\n",
    "2. https://pdfs.semanticscholar.org/450c/a19932fcef1ca6d0442cbf52fec38fb9d1e5.pdf?_ga=2.127701316.833949504.1587235878-358525363.1587235878\n",
    "3. https://docs.gimp.org/2.6/en/plug-in-convmatrix.html\n",
    "4. https://arxiv.org/pdf/1609.04112.pdf\n",
    "5. https://arxiv.org/pdf/1502.01852.pdf\n",
    "6. http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf\n",
    "7. https://www.cs.ryerson.ca/~aharley/vis/conv/\n",
    "8. https://peterroelants.github.io/posts/cross-entropy-softmax/\n",
    "9. https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation a set of images of cats and dogs are given, the CNN will be trained using them to predict if a given image is of a cat or that of a dog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
