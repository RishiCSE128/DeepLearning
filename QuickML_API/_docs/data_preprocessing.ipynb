{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_vars = {\n",
    "    \"DATASET_FILE_PREFIX\" : \"C:\\\\Users\\\\sapta\\\\Documents\\\\git\\\\DeepLearning\\\\QuickML_API\\\\_docs\\\\dataset\\\\\",\n",
    "\n",
    "    \"split_profile\" : {\n",
    "        'independent_vars' : ['Country', 'Age', 'Salary'],\n",
    "        'dependent_vars' : ['Purchased'],\n",
    "        'train_size' : 0.7\n",
    "    },\n",
    "\n",
    "    \"impute_strategy\" : {\n",
    "            'missing_value' : np.nan,\n",
    "            'strategy': 'mean'\n",
    "    },\n",
    "\n",
    "    \"categorical_cols\" : {\n",
    "        'independent' : ['Country'],\n",
    "        'dependent' : ['Purchased']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tab(df : pd.DataFrame, head = False) -> None:\n",
    "    \"\"\"prints pandas dataframe in tabular form \n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe to print\n",
    "        head (bool): if set to False (default) prints whole table\n",
    "    \"\"\"\n",
    "\n",
    "    if head:\n",
    "        print(tabulate(df.head(), headers = 'keys', tablefmt = 'pretty'))\n",
    "    else:\n",
    "        print(tabulate(df, headers = 'keys', tablefmt = 'pretty'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_filename):\n",
    "    DATASET_FILE_PREFIX = global_vars['DATASET_FILE_PREFIX']\n",
    "    source_dataframe = pd.read_csv(DATASET_FILE_PREFIX + dataset_filename)\n",
    "    return source_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+---------+-----------+\n",
      "|   | Country | Age  | Salary  | Purchased |\n",
      "+---+---------+------+---------+-----------+\n",
      "| 0 | France  | 44.0 | 72000.0 |    No     |\n",
      "| 1 |  Spain  | 27.0 | 48000.0 |    Yes    |\n",
      "| 2 | Germany | 30.0 | 54000.0 |    No     |\n",
      "| 3 |  Spain  | 38.0 | 61000.0 |    No     |\n",
      "| 4 | Germany | 40.0 |   nan   |    Yes    |\n",
      "| 5 | France  | 35.0 | 58000.0 |    Yes    |\n",
      "| 6 |  Spain  | nan  | 52000.0 |    No     |\n",
      "| 7 | France  | 48.0 | 79000.0 |    Yes    |\n",
      "| 8 | Germany | 50.0 | 83000.0 |    No     |\n",
      "| 9 | France  | 37.0 | 67000.0 |    Yes    |\n",
      "+---+---------+------+---------+-----------+\n"
     ]
    }
   ],
   "source": [
    "source_dataframe = load_dataset(dataset_filename=\"data_preprocessing.csv\")\n",
    "print_tab(source_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dependent - Independent variable Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DI_split(source_dataframe : pd.DataFrame, conv_to_np = False) -> dict:\n",
    "    \n",
    "    split_profile = global_vars['split_profile']\n",
    "    X = source_dataframe[ split_profile['independent_vars'] ]\n",
    "    y = source_dataframe[ split_profile['dependent_vars'] ]\n",
    "\n",
    "    if conv_to_np:\n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "    \n",
    "    return {'X':X , 'y':y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independent (X)\n",
      "+---+---------+------+---------+\n",
      "|   | Country | Age  | Salary  |\n",
      "+---+---------+------+---------+\n",
      "| 0 | France  | 44.0 | 72000.0 |\n",
      "| 1 |  Spain  | 27.0 | 48000.0 |\n",
      "| 2 | Germany | 30.0 | 54000.0 |\n",
      "| 3 |  Spain  | 38.0 | 61000.0 |\n",
      "| 4 | Germany | 40.0 |   nan   |\n",
      "| 5 | France  | 35.0 | 58000.0 |\n",
      "| 6 |  Spain  | nan  | 52000.0 |\n",
      "| 7 | France  | 48.0 | 79000.0 |\n",
      "| 8 | Germany | 50.0 | 83000.0 |\n",
      "| 9 | France  | 37.0 | 67000.0 |\n",
      "+---+---------+------+---------+\n",
      "Dependent (y)\n",
      "+---+-----------+\n",
      "|   | Purchased |\n",
      "+---+-----------+\n",
      "| 0 |    No     |\n",
      "| 1 |    Yes    |\n",
      "| 2 |    No     |\n",
      "| 3 |    No     |\n",
      "| 4 |    Yes    |\n",
      "| 5 |    Yes    |\n",
      "| 6 |    No     |\n",
      "| 7 |    Yes    |\n",
      "| 8 |    No     |\n",
      "| 9 |    Yes    |\n",
      "+---+-----------+\n"
     ]
    }
   ],
   "source": [
    "split_profile = global_vars['split_profile']\n",
    "\n",
    "splitted_data = get_DI_split(source_dataframe=source_dataframe)\n",
    "print('Independent (X)')\n",
    "print_tab(splitted_data[\"X\"])\n",
    "\n",
    "print('Dependent (y)')\n",
    "print_tab(splitted_data[\"y\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Remove Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_list_with_null(dataframe : pd.DataFrame) -> list:\n",
    "\n",
    "    col_list_with_null = [] \n",
    "    for column in dataframe.columns:\n",
    "        if dataframe[column].isnull().any():\n",
    "            col_list_with_null.append(column)\n",
    "    return col_list_with_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Salary']\n"
     ]
    }
   ],
   "source": [
    "col = get_col_list_with_null(dataframe=splitted_data[\"X\"])\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_data(dataframe : pd.DataFrame ) -> pd.DataFrame:\n",
    "    \n",
    "    impute_strategy = global_vars['impute_strategy']\n",
    "\n",
    "    # instantiate imputer object\n",
    "    si = SimpleImputer(missing_values=impute_strategy['missing_value'], \n",
    "                       strategy=impute_strategy['strategy'])\n",
    "\n",
    "    # get all column names with missing data\n",
    "    col_list_with_null = get_col_list_with_null(dataframe=dataframe)\n",
    "\n",
    "    # replace all missing values \n",
    "    df_copy = dataframe.copy()\n",
    "    df_copy[col_list_with_null] = si.fit(df_copy[col_list_with_null]).transform(df_copy[col_list_with_null])\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------------------+-------------------+\n",
      "|   | Country |        Age        |      Salary       |\n",
      "+---+---------+-------------------+-------------------+\n",
      "| 0 | France  |       44.0        |      72000.0      |\n",
      "| 1 |  Spain  |       27.0        |      48000.0      |\n",
      "| 2 | Germany |       30.0        |      54000.0      |\n",
      "| 3 |  Spain  |       38.0        |      61000.0      |\n",
      "| 4 | Germany |       40.0        | 63777.77777777778 |\n",
      "| 5 | France  |       35.0        |      58000.0      |\n",
      "| 6 |  Spain  | 38.77777777777778 |      52000.0      |\n",
      "| 7 | France  |       48.0        |      79000.0      |\n",
      "| 8 | Germany |       50.0        |      83000.0      |\n",
      "| 9 | France  |       37.0        |      67000.0      |\n",
      "+---+---------+-------------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "# get splitted DF\n",
    "split_df = get_DI_split(source_dataframe=source_dataframe)\n",
    "\n",
    "# get imputed DF\n",
    "splitted_data[\"X\"] = remove_missing_data(dataframe=splitted_data[\"X\"])\n",
    "\n",
    "# print imputed\n",
    "print_tab(splitted_data[\"X\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Encoding of Categorical Variables \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Individual implementaion of encoders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1. Loding dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical  Columns = ['Country']\n",
      "+---+---------+-------------------+-------------------+\n",
      "|   | Country |        Age        |      Salary       |\n",
      "+---+---------+-------------------+-------------------+\n",
      "| 0 | France  |       44.0        |      72000.0      |\n",
      "| 1 |  Spain  |       27.0        |      48000.0      |\n",
      "| 2 | Germany |       30.0        |      54000.0      |\n",
      "| 3 |  Spain  |       38.0        |      61000.0      |\n",
      "| 4 | Germany |       40.0        | 63777.77777777778 |\n",
      "| 5 | France  |       35.0        |      58000.0      |\n",
      "| 6 |  Spain  | 38.77777777777778 |      52000.0      |\n",
      "| 7 | France  |       48.0        |      79000.0      |\n",
      "| 8 | Germany |       50.0        |      83000.0      |\n",
      "| 9 | France  |       37.0        |      67000.0      |\n",
      "+---+---------+-------------------+-------------------+\n",
      "Categorical  Columns = ['Purchased']\n",
      "+---+-----------+\n",
      "|   | Purchased |\n",
      "+---+-----------+\n",
      "| 0 |    No     |\n",
      "| 1 |    Yes    |\n",
      "| 2 |    No     |\n",
      "| 3 |    No     |\n",
      "| 4 |    Yes    |\n",
      "| 5 |    Yes    |\n",
      "| 6 |    No     |\n",
      "| 7 |    Yes    |\n",
      "| 8 |    No     |\n",
      "| 9 |    Yes    |\n",
      "+---+-----------+\n"
     ]
    }
   ],
   "source": [
    "dataframe_X = splitted_data[\"X\"]\n",
    "dataframe_y = splitted_data[\"y\"]\n",
    "\n",
    "catagorical_cols_X = global_vars[\"categorical_cols\"][\"independent\"]\n",
    "catagorical_cols_y = global_vars[\"categorical_cols\"][\"dependent\"]\n",
    "\n",
    "print(f'Categorical  Columns = {catagorical_cols_X}')\n",
    "print_tab(dataframe_X)\n",
    "\n",
    "print(f'Categorical  Columns = {catagorical_cols_y}')\n",
    "print_tab(dataframe_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X after encoding\n",
      "+---+---------+-------------------+-------------------+\n",
      "|   | Country |        Age        |      Salary       |\n",
      "+---+---------+-------------------+-------------------+\n",
      "| 0 |   0.0   |       44.0        |      72000.0      |\n",
      "| 1 |   2.0   |       27.0        |      48000.0      |\n",
      "| 2 |   1.0   |       30.0        |      54000.0      |\n",
      "| 3 |   2.0   |       38.0        |      61000.0      |\n",
      "| 4 |   1.0   |       40.0        | 63777.77777777778 |\n",
      "| 5 |   0.0   |       35.0        |      58000.0      |\n",
      "| 6 |   2.0   | 38.77777777777778 |      52000.0      |\n",
      "| 7 |   0.0   |       48.0        |      79000.0      |\n",
      "| 8 |   1.0   |       50.0        |      83000.0      |\n",
      "| 9 |   0.0   |       37.0        |      67000.0      |\n",
      "+---+---------+-------------------+-------------------+\n",
      "y after encoding\n",
      "+---+-----------+\n",
      "|   | Purchased |\n",
      "+---+-----------+\n",
      "| 0 |     0     |\n",
      "| 1 |     1     |\n",
      "| 2 |     0     |\n",
      "| 3 |     0     |\n",
      "| 4 |     1     |\n",
      "| 5 |     1     |\n",
      "| 6 |     0     |\n",
      "| 7 |     1     |\n",
      "| 8 |     0     |\n",
      "| 9 |     1     |\n",
      "+---+-----------+\n"
     ]
    }
   ],
   "source": [
    "dataframe_X = splitted_data[\"X\"]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "dataframe_X = splitted_data[\"X\"].copy()\n",
    "dataframe_y = splitted_data[\"y\"].copy()\n",
    "\n",
    "for column in catagorical_cols_X:\n",
    "    dataframe_X[column] = label_encoder.fit_transform(dataframe_X[column])\n",
    "\n",
    "for column in catagorical_cols_y:\n",
    "    dataframe_y[column] = label_encoder.fit_transform(dataframe_y[column])\n",
    "\n",
    "print(\"X after encoding\")\n",
    "print_tab(dataframe_X)\n",
    "\n",
    "print(\"y after encoding\")\n",
    "print_tab(dataframe_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3. One Hot Encoding (OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------------------+-------------------+-----+-----+-----+\n",
      "|   | Country |        Age        |      Salary       |  0  |  1  |  2  |\n",
      "+---+---------+-------------------+-------------------+-----+-----+-----+\n",
      "| 0 | France  |       44.0        |      72000.0      | 1.0 | 0.0 | 0.0 |\n",
      "| 1 |  Spain  |       27.0        |      48000.0      | 0.0 | 0.0 | 1.0 |\n",
      "| 2 | Germany |       30.0        |      54000.0      | 0.0 | 1.0 | 0.0 |\n",
      "| 3 |  Spain  |       38.0        |      61000.0      | 0.0 | 0.0 | 1.0 |\n",
      "| 4 | Germany |       40.0        | 63777.77777777778 | 0.0 | 1.0 | 0.0 |\n",
      "| 5 | France  |       35.0        |      58000.0      | 1.0 | 0.0 | 0.0 |\n",
      "| 6 |  Spain  | 38.77777777777778 |      52000.0      | 0.0 | 0.0 | 1.0 |\n",
      "| 7 | France  |       48.0        |      79000.0      | 1.0 | 0.0 | 0.0 |\n",
      "| 8 | Germany |       50.0        |      83000.0      | 0.0 | 1.0 | 0.0 |\n",
      "| 9 | France  |       37.0        |      67000.0      | 1.0 | 0.0 | 0.0 |\n",
      "+---+---------+-------------------+-------------------+-----+-----+-----+\n"
     ]
    }
   ],
   "source": [
    "dataframe_X = splitted_data[\"X\"].copy()\n",
    "for column in catagorical_cols_X:\n",
    "    oh_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    oh_df = pd.DataFrame(oh_encoder.fit_transform(dataframe_X[[column]]).toarray())\n",
    "    dataframe_X = dataframe_X.join(oh_df)\n",
    "    \n",
    "print_tab(dataframe_X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4. OHE with Dummy variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+-----------------+---------------+\n",
      "|   | Country_France | Country_Germany | Country_Spain |\n",
      "+---+----------------+-----------------+---------------+\n",
      "| 0 |       1        |        0        |       0       |\n",
      "| 1 |       0        |        0        |       1       |\n",
      "| 2 |       0        |        1        |       0       |\n",
      "| 3 |       0        |        0        |       1       |\n",
      "| 4 |       0        |        1        |       0       |\n",
      "| 5 |       1        |        0        |       0       |\n",
      "| 6 |       0        |        0        |       1       |\n",
      "| 7 |       1        |        0        |       0       |\n",
      "| 8 |       0        |        1        |       0       |\n",
      "| 9 |       1        |        0        |       0       |\n",
      "+---+----------------+-----------------+---------------+\n",
      "+---+-------------------+-------------------+----------------+-----------------+---------------+\n",
      "|   |        Age        |      Salary       | Country_France | Country_Germany | Country_Spain |\n",
      "+---+-------------------+-------------------+----------------+-----------------+---------------+\n",
      "| 0 |       44.0        |      72000.0      |      1.0       |       0.0       |      0.0      |\n",
      "| 1 |       27.0        |      48000.0      |      0.0       |       0.0       |      1.0      |\n",
      "| 2 |       30.0        |      54000.0      |      0.0       |       1.0       |      0.0      |\n",
      "| 3 |       38.0        |      61000.0      |      0.0       |       0.0       |      1.0      |\n",
      "| 4 |       40.0        | 63777.77777777778 |      0.0       |       1.0       |      0.0      |\n",
      "| 5 |       35.0        |      58000.0      |      1.0       |       0.0       |      0.0      |\n",
      "| 6 | 38.77777777777778 |      52000.0      |      0.0       |       0.0       |      1.0      |\n",
      "| 7 |       48.0        |      79000.0      |      1.0       |       0.0       |      0.0      |\n",
      "| 8 |       50.0        |      83000.0      |      0.0       |       1.0       |      0.0      |\n",
      "| 9 |       37.0        |      67000.0      |      1.0       |       0.0       |      0.0      |\n",
      "+---+-------------------+-------------------+----------------+-----------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "dataframe_X = splitted_data[\"X\"].copy()\n",
    "for column in catagorical_cols_X:\n",
    "    # one-hot encoding for each categical var\n",
    "    dummy_df = pd.get_dummies(dataframe_X[column], columns=[column], prefix=column)\n",
    "    print_tab(dummy_df)  # dummy var table for each encoding \n",
    "    dataframe_X = dataframe_X.join(dummy_df).drop(column, axis = 1) # upate dataframe by joining \n",
    "    \n",
    "print_tab(dataframe_X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Categotical Encoding with OHE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  cat_endcoing(dataframe : pd.DataFrame, categorical_cols : list, ohe = True):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        dataframe_X (pd.DataFrame): _description_\n",
    "        categorical_cols (list): _description_\n",
    "        ohe (bool): _description__\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    df = dataframe.copy()\n",
    "    if ohe:  # one hot encoding \n",
    "        for column in categorical_cols:\n",
    "            dummy_df = pd.get_dummies(df[column], columns=[column], prefix=column)  # dummy var table for each encoding \n",
    "            df = df.join(dummy_df).drop(column, axis = 1) # upate dataframe by joining \n",
    "\n",
    "    else:    # label encoding\n",
    "        label_encoder = LabelEncoder() \n",
    "        for column in categorical_cols:\n",
    "            df[column] = label_encoder.fit_transform(df[column])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------------+----------------+-----------------+---------------+\n",
      "|   |        Age        |      Salary       | Country_France | Country_Germany | Country_Spain |\n",
      "+---+-------------------+-------------------+----------------+-----------------+---------------+\n",
      "| 0 |       44.0        |      72000.0      |      1.0       |       0.0       |      0.0      |\n",
      "| 1 |       27.0        |      48000.0      |      0.0       |       0.0       |      1.0      |\n",
      "| 2 |       30.0        |      54000.0      |      0.0       |       1.0       |      0.0      |\n",
      "| 3 |       38.0        |      61000.0      |      0.0       |       0.0       |      1.0      |\n",
      "| 4 |       40.0        | 63777.77777777778 |      0.0       |       1.0       |      0.0      |\n",
      "| 5 |       35.0        |      58000.0      |      1.0       |       0.0       |      0.0      |\n",
      "| 6 | 38.77777777777778 |      52000.0      |      0.0       |       0.0       |      1.0      |\n",
      "| 7 |       48.0        |      79000.0      |      1.0       |       0.0       |      0.0      |\n",
      "| 8 |       50.0        |      83000.0      |      0.0       |       1.0       |      0.0      |\n",
      "| 9 |       37.0        |      67000.0      |      1.0       |       0.0       |      0.0      |\n",
      "+---+-------------------+-------------------+----------------+-----------------+---------------+\n",
      "+---+-----------+\n",
      "|   | Purchased |\n",
      "+---+-----------+\n",
      "| 0 |     0     |\n",
      "| 1 |     1     |\n",
      "| 2 |     0     |\n",
      "| 3 |     0     |\n",
      "| 4 |     1     |\n",
      "| 5 |     1     |\n",
      "| 6 |     0     |\n",
      "| 7 |     1     |\n",
      "| 8 |     0     |\n",
      "| 9 |     1     |\n",
      "+---+-----------+\n"
     ]
    }
   ],
   "source": [
    "dataframe_X = cat_endcoing(dataframe=dataframe_X, categorical_cols=global_vars['categorical_cols']['independent'], ohe=True)\n",
    "dataframe_y = cat_endcoing(dataframe=dataframe_y, categorical_cols=global_vars['categorical_cols']['dependent'], ohe=False)\n",
    "\n",
    "print_tab(dataframe_X)\n",
    "print_tab(dataframe_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_split(dataframe_X : pd.DataFrame, dataframe_y : pd.DataFrame) -> dict :\n",
    "    \"\"\"performs train-test-split on the given dataset\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): source dataframe \n",
    "        split_profile (dict): dictionary must cotain a key 'tt_ratio' (float) [0.0 - 1.0] denotes training proportion \n",
    "\n",
    "    Returns:\n",
    "        dict: _description_\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataframe_X, dataframe_y, train_size=global_vars['split_profile']['train_size'])\n",
    "    return {\n",
    "        'X_train' : X_train,\n",
    "        'X_test' : X_test,\n",
    "        'y_train' : y_train,\n",
    "        'y_test' : y_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "+---+-------------------+-------------------+----------------+-----------------+---------------+\n",
      "|   |        Age        |      Salary       | Country_France | Country_Germany | Country_Spain |\n",
      "+---+-------------------+-------------------+----------------+-----------------+---------------+\n",
      "| 0 |       44.0        |      72000.0      |      1.0       |       0.0       |      0.0      |\n",
      "| 9 |       37.0        |      67000.0      |      1.0       |       0.0       |      0.0      |\n",
      "| 5 |       35.0        |      58000.0      |      1.0       |       0.0       |      0.0      |\n",
      "| 8 |       50.0        |      83000.0      |      0.0       |       1.0       |      0.0      |\n",
      "| 7 |       48.0        |      79000.0      |      1.0       |       0.0       |      0.0      |\n",
      "| 4 |       40.0        | 63777.77777777778 |      0.0       |       1.0       |      0.0      |\n",
      "| 6 | 38.77777777777778 |      52000.0      |      0.0       |       0.0       |      1.0      |\n",
      "+---+-------------------+-------------------+----------------+-----------------+---------------+\n",
      "X_test\n",
      "+---+------+---------+----------------+-----------------+---------------+\n",
      "|   | Age  | Salary  | Country_France | Country_Germany | Country_Spain |\n",
      "+---+------+---------+----------------+-----------------+---------------+\n",
      "| 3 | 38.0 | 61000.0 |      0.0       |       0.0       |      1.0      |\n",
      "| 1 | 27.0 | 48000.0 |      0.0       |       0.0       |      1.0      |\n",
      "| 2 | 30.0 | 54000.0 |      0.0       |       1.0       |      0.0      |\n",
      "+---+------+---------+----------------+-----------------+---------------+\n",
      "y_train\n",
      "+---+-----------+\n",
      "|   | Purchased |\n",
      "+---+-----------+\n",
      "| 0 |     0     |\n",
      "| 9 |     1     |\n",
      "| 5 |     1     |\n",
      "| 8 |     0     |\n",
      "| 7 |     1     |\n",
      "| 4 |     1     |\n",
      "| 6 |     0     |\n",
      "+---+-----------+\n",
      "y_test\n",
      "+---+-----------+\n",
      "|   | Purchased |\n",
      "+---+-----------+\n",
      "| 3 |     0     |\n",
      "| 1 |     1     |\n",
      "| 2 |     0     |\n",
      "+---+-----------+\n"
     ]
    }
   ],
   "source": [
    "result = tt_split(dataframe_X=dataframe_X, dataframe_y=dataframe_y)\n",
    "\n",
    "for key in result.keys():\n",
    "    print(key)\n",
    "    print_tab(result[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scalling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scalling(tt_splitted_dfs : dict , scale_dummies = True) ->dict:\n",
    "  \"\"\"_summary_\n",
    "\n",
    "  Args:\n",
    "      tt_splitted_dfs (dict): _description_\n",
    "      scale_dummies (bool, optional): _description_. Defaults to True.\n",
    "\n",
    "  Returns:\n",
    "      dict: _description_\n",
    "  \"\"\"\n",
    "    \n",
    "  sc_X = StandardScaler()\n",
    "  if not scale_dummies:\n",
    "    # non-categoriccal independent vars\n",
    "    scalable_features = list(set(global_vars['split_profile']['independent_vars']) - set(global_vars['categorical_cols']['independent']))\n",
    "\n",
    "  return{\n",
    "    'X_train' : sc_X.fit_transform(tt_splitted_dfs['X_train']),\n",
    "    'X_test' : sc_X.transform(tt_splitted_dfs['X_test']),\n",
    "    'y_train' : tt_splitted_dfs['y_train'],\n",
    "    'y_test' : tt_splitted_dfs['y_test']\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "+----------------------+----------------------+---------------------+---------------------+--------------------+\n",
      "|          0           |          1           |          2          |          3          |         4          |\n",
      "+----------------------+----------------------+---------------------+---------------------+--------------------+\n",
      "|  0.4150371955802574  |  0.4069530487552628  | 0.8660254037844387  | -0.6324555320336759 | -0.408248290463863 |\n",
      "| -0.9209584485868486  | -0.08046219975389231 | 0.8660254037844387  | -0.6324555320336759 | -0.408248290463863 |\n",
      "| -1.3026714897774505  | -0.9578096470703715  | 0.8660254037844387  | -0.6324555320336759 | -0.408248290463863 |\n",
      "|  1.5601763191520626  |  1.479266595475404   | -1.1547005383792517 |  1.58113883008419   | -0.408248290463863 |\n",
      "|  1.1784632779614608  |   1.08933439666808   | 0.8660254037844387  | -0.6324555320336759 | -0.408248290463863 |\n",
      "| -0.34838888680094604 | -0.3945742487931253  | -1.1547005383792517 |  1.58113883008419   | -0.408248290463863 |\n",
      "| -0.5816579675285358  | -1.5427079452813577  | -1.1547005383792517 | -0.6324555320336759 | 2.4494897427831783 |\n",
      "+----------------------+----------------------+---------------------+---------------------+--------------------+\n",
      "X_test\n",
      "+---------------------+---------------------+---------------------+---------------------+--------------------+\n",
      "|          0          |          1          |          2          |          3          |         4          |\n",
      "+---------------------+---------------------+---------------------+---------------------+--------------------+\n",
      "| -0.7301019279915477 | -0.6653604979648785 | -1.1547005383792517 | -0.6324555320336759 | 2.4494897427831783 |\n",
      "| -2.829523654539857  | -1.9326401440886818 | -1.1547005383792517 | -0.6324555320336759 | 2.4494897427831783 |\n",
      "| -2.2569540927539546 | -1.3477418458776957 | -1.1547005383792517 |  1.58113883008419   | -0.408248290463863 |\n",
      "+---------------------+---------------------+---------------------+---------------------+--------------------+\n",
      "y_train\n",
      "+---+-----------+\n",
      "|   | Purchased |\n",
      "+---+-----------+\n",
      "| 0 |     0     |\n",
      "| 9 |     1     |\n",
      "| 5 |     1     |\n",
      "| 8 |     0     |\n",
      "| 7 |     1     |\n",
      "| 4 |     1     |\n",
      "| 6 |     0     |\n",
      "+---+-----------+\n",
      "y_test\n",
      "+---+-----------+\n",
      "|   | Purchased |\n",
      "+---+-----------+\n",
      "| 3 |     0     |\n",
      "| 1 |     1     |\n",
      "| 2 |     0     |\n",
      "+---+-----------+\n"
     ]
    }
   ],
   "source": [
    "scalled_dfs = feature_scalling(tt_splitted_dfs=result, scale_dummies=False)\n",
    "\n",
    "for key in result.keys():\n",
    "    print(key)\n",
    "    print_tab(scalled_dfs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [1,2,3]\n",
    "B = [2]\n",
    "\n",
    "list(set(A) - set(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "266c1c55aa6f7dee84faf496073a37a295dea7231ffafeee013be1d7c83a8c33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
